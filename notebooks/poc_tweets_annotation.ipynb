{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pigeonXT import annotate\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash():\n",
    "    return \"%08x\" % random.getrandbits(32)\n",
    "\n",
    "\n",
    "hash = hash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_HOST = \"mongodb://localhost/twitterdb\"\n",
    "client = MongoClient(MONGO_HOST)\n",
    "raw_tweets = client.twitterdb.tweets_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>metadata</th>\n",
       "      <th>source</th>\n",
       "      <th>...</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>lang</th>\n",
       "      <th>query</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>62f3fbe2ef45b02417c6518a</td>\n",
       "      <td>Wed Aug 10 04:47:56 +0000 2022</td>\n",
       "      <td>1557227224293597186</td>\n",
       "      <td>1557227224293597186</td>\n",
       "      <td>@lybrjack Uma boa quest√£o, um amigo meu pergun...</td>\n",
       "      <td>False</td>\n",
       "      <td>[10, 270]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'pt', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>pt</td>\n",
       "      <td>jeito de gay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>62f3ef217a58ae552109c8fe</td>\n",
       "      <td>Wed Aug 10 14:04:29 +0000 2022</td>\n",
       "      <td>1557367283856596992</td>\n",
       "      <td>1557367283856596992</td>\n",
       "      <td>@JoaquinTeixeira @jairbolsonaro sei n√£o, esse ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[32, 73]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'pt', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>pt</td>\n",
       "      <td>cara de macaco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id                      created_at  \\\n",
       "1491  62f3fbe2ef45b02417c6518a  Wed Aug 10 04:47:56 +0000 2022   \n",
       "450   62f3ef217a58ae552109c8fe  Wed Aug 10 14:04:29 +0000 2022   \n",
       "\n",
       "                       id               id_str  \\\n",
       "1491  1557227224293597186  1557227224293597186   \n",
       "450   1557367283856596992  1557367283856596992   \n",
       "\n",
       "                                              full_text  truncated  \\\n",
       "1491  @lybrjack Uma boa quest√£o, um amigo meu pergun...      False   \n",
       "450   @JoaquinTeixeira @jairbolsonaro sei n√£o, esse ...      False   \n",
       "\n",
       "     display_text_range                                           entities  \\\n",
       "1491          [10, 270]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "450            [32, 73]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                               metadata  \\\n",
       "1491  {'iso_language_code': 'pt', 'result_type': 're...   \n",
       "450   {'iso_language_code': 'pt', 'result_type': 're...   \n",
       "\n",
       "                                                 source  ...  favorite_count  \\\n",
       "1491  <a href=\"https://mobile.twitter.com\" rel=\"nofo...  ...               0   \n",
       "450   <a href=\"https://mobile.twitter.com\" rel=\"nofo...  ...               0   \n",
       "\n",
       "     favorited  retweeted lang           query extended_entities  \\\n",
       "1491     False      False   pt    jeito de gay               NaN   \n",
       "450      False      False   pt  cara de macaco               NaN   \n",
       "\n",
       "     possibly_sensitive quoted_status_id quoted_status_id_str quoted_status  \n",
       "1491                NaN              NaN                  NaN           NaN  \n",
       "450                 NaN              NaN                  NaN           NaN  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.DataFrame(list(raw_tweets.find()))\n",
    "raw_df.sample(2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1555630597527199746</td>\n",
       "      <td>@0ravl4 @hoje_no Al√©m de petralha a safada ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1557015903224700929</td>\n",
       "      <td>N√ÉO existe \"coxinha sem massa\",bando de burro pqp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1556198185059684362</td>\n",
       "      <td>@heldermaldonado Coxinha burro!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1555581110880436224</td>\n",
       "      <td>Ser petista √© ser burro para mas de metro , pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1554478359375126528</td>\n",
       "      <td>Burro burro burro burro burro me ofereceram um...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text\n",
       "0  1555630597527199746  @0ravl4 @hoje_no Al√©m de petralha a safada ain...\n",
       "1  1557015903224700929  N√ÉO existe \"coxinha sem massa\",bando de burro pqp\n",
       "2  1556198185059684362                   @heldermaldonado Coxinha burro!!\n",
       "3  1555581110880436224  Ser petista √© ser burro para mas de metro , pa...\n",
       "4  1554478359375126528  Burro burro burro burro burro me ofereceram um..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_df = raw_df.copy()[[\"id\", \"full_text\"]]\n",
    "public_df.drop_duplicates(inplace=True)\n",
    "public_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1557422001073037312</td>\n",
       "      <td>eu sou muito boiola por essas duas sim ü•∫ü§èüèº\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1557213357341646853</td>\n",
       "      <td>@LeonelRadde E a Rosca, \\nQueima ou n√£o Queima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>1557179504908460032</td>\n",
       "      <td>@jandira_feghali Chuta que √© macumba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1557415987045171202</td>\n",
       "      <td>vai se foder puta desgra√ßada vagabunda ego√≠sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>1557434423527849984</td>\n",
       "      <td>me sentindo gord*o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                          full_text\n",
       "259   1557422001073037312  eu sou muito boiola por essas duas sim ü•∫ü§èüèº\\n\\n...\n",
       "300   1557213357341646853  @LeonelRadde E a Rosca, \\nQueima ou n√£o Queima...\n",
       "977   1557179504908460032               @jandira_feghali Chuta que √© macumba\n",
       "137   1557415987045171202  vai se foder puta desgra√ßada vagabunda ego√≠sta...\n",
       "2099  1557434423527849984                                 me sentindo gord*o"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = public_df.sample(20)\n",
    "sample.to_csv(f\"../data/input_test_data_{hash}.csv\", index=False)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 20 of 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f33e3abfd5409a8c2269a7499e8b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 20 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f89f5ed71e40c2bc637dd9b01505c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(ToggleButton(value=False, description='political'), ToggleButton(value=False, de‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab01b1397cb844ca88b542b67e4c6685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu sou muito boiola por essas duas sim ü•∫ü§èüèº\n",
      "\n",
      "#motherlandforsalem\n",
      "\n",
      "https://t.co/wax5SnkXof ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@LeonelRadde E a Rosca, \n",
      "Queima ou n√£o Queima??\n",
      "üòéü§£ü§£ü§£ü§£ ['lgbtphobia']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@jandira_feghali Chuta que √© macumba ['religion']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vai se foder puta desgra√ßada vagabunda ego√≠sta ignorante cadela azeda idiota ingrata irracional inconsequente ot√°ria audaciosa burra cu de franjo estranha chata atropelada cachorra merda vaca imbecil arrombada mimizenta esquisita esquizofrenica baranga lixo paran√≥ica e mal comida ['sexism']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me sentindo gord*o ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n√£o tem gra√ßa nenhuma fazer piada com isso, imbecil ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@chris_schettine Eu tinha o h√°bito de falar sobre padr√£o est√©tico question√°vel como \"baianice\" \"coisa de baiano\" \n",
      "Casei com uma filha de Baianos kkkkkkkkkkk ['xenophobia']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ritmodetorcida Os cara quebram o port√£o pra invadir o lado do Vasco, em maior n√∫mero n√£o invadi e fica fazendo grito de macaco igual maluco... muito idiotas e peid√£o ainda por cima. ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "um bando de crente defendendo a cusadora pompeo, que vida triste ['religion']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@lecibrandao Vagabunda igual  o  #LuLADRAO ['political']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@thigagliasso Como diz o Guilherme Fiuza, √© a esquerda caviar! ['political']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bolsonaro nunca se preocupou com os mais pobres. Nunca se preocupou com quem passa fome. Tentou de todas as maneiras dar um aux√≠lio emergencial menor. E cancelou o aux√≠lio sempre que teve oportunidade. Quando viu que esse aux√≠lio compra votos dos mais necessitados, ele defendeu. https://t.co/OqIvxNutpW ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@luanaserra @hppoderoso @otiagoabreu Como figurinha da √°rea eu discordo desse argumento. A gente tem que puxar o bonde junto. Tem muito espa√ßo pro autismo? Ent√£o vai o autista e fala sobre as outras defici√™ncias para o p√∫blico dele... ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caralho que √≥dio desse bando de filha da puta‚Ä¶ eu pedi um caf√© com cookie e vou tomar meia hora de sol pra n√£o quebrar a cara de ngm‚Ä¶ ['other', 'not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@mariaislc Puta n√£o q eu n sou tuas nega ['sexism', 'racism']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hj uma safada queria me passar nota falsa vontade de dar na cara dela q √≥dio ['sexism']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@reveloud ja pode contar pros seus seguidores q vc eh um velho tarado de 52 anos ['ageism']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@douglasdelete @CLMerlo Pesquisa ai a divida do teu time, v√™ l√° quem deve mais. mongol burro! ['ableism']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vim fazer comprinhas no supermercado e comprei tanta besteira chocolates, doces etc parece que terminei mais um namoro mas √© s√≥ a solid√£o do twink favelado mesmo https://t.co/3F2LWE1ezD ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J√° fiz assim, mas eu era jovem e burro. https://t.co/1M3LcbyrVT ['not_applicable']\n",
      "Annotation done.\n"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "    \"political\",\n",
    "    \"sexism\",\n",
    "    \"lgbtphobia\",\n",
    "    \"racism\",\n",
    "    \"aporophobia\",\n",
    "    \"xenophobia\",\n",
    "    \"ableism\",\n",
    "    \"ageism\",\n",
    "    \"religion\",\n",
    "    \"body_shame\",\n",
    "    \"other\",\n",
    "    \"not_applicable\",\n",
    "]\n",
    "\n",
    "shortLabels = [\"PL\", \"SX\", \"LGBT\", \"RC\", \"AP\", \"XP\", \"AB\", \"AG\", \"RL\", \"BS\", \"OT\", \"NA\"]\n",
    "\n",
    "\n",
    "def setLabels(labels, numClasses):\n",
    "    row = np.zeros([numClasses], dtype=np.uint8)\n",
    "    row[labels] = 1\n",
    "    return row\n",
    "\n",
    "\n",
    "def labelPortion(\n",
    "    inputFile,\n",
    "    labels=[\"yes\", \"no\"],\n",
    "    outputFile=f\"../data/output_test_data_{hash}.csv\",\n",
    "    portionSize=20,\n",
    "    textColumn=\"full_text\",\n",
    "    shortLabels=None,\n",
    "):\n",
    "\n",
    "    if shortLabels:\n",
    "        shortLabels = shortLabels\n",
    "    else:\n",
    "        shortLabels = labels\n",
    "\n",
    "    out = Path(outputFile)\n",
    "    if out.exists():\n",
    "        outdf = pd.read_csv(out)\n",
    "        currentId = outdf.index.max() + 1\n",
    "    else:\n",
    "        currentId = 0\n",
    "\n",
    "    indf = pd.read_csv(inputFile)\n",
    "    examplesInFile = len(indf)\n",
    "    indf = indf.loc[currentId : currentId + portionSize - 1]\n",
    "    actualPortionSize = len(indf)\n",
    "    print(f\"{currentId + 1} - {currentId + actualPortionSize} of {examplesInFile}\")\n",
    "    sentences = indf[textColumn].tolist()\n",
    "\n",
    "    for label in shortLabels:\n",
    "        indf[label] = None\n",
    "\n",
    "    def updateRow(example, selectedLabels):\n",
    "        print(example, selectedLabels)\n",
    "        labs = setLabels([labels.index(y) for y in selectedLabels], len(labels))\n",
    "        indf.loc[indf[textColumn] == example, shortLabels] = labs\n",
    "\n",
    "    def finalProcessing(annotations):\n",
    "        if out.exists():\n",
    "            prevdata = pd.read_csv(out)\n",
    "            outdata = pd.concat([prevdata, indf]).reset_index(drop=True)\n",
    "        else:\n",
    "            outdata = indf.copy()\n",
    "        outdata.to_csv(out, index=False)\n",
    "\n",
    "    _ = annotate(\n",
    "        sentences,\n",
    "        options=labels,\n",
    "        task_type=\"multilabel-classification\",\n",
    "        buttons_in_a_row=3,\n",
    "        reset_buttons_after_click=True,\n",
    "        include_next=False,\n",
    "        include_back=False,\n",
    "        example_process_fn=updateRow,\n",
    "        final_process_fn=finalProcessing,\n",
    "    )\n",
    "    return indf\n",
    "\n",
    "\n",
    "def getAnnotationsCountPerlabel(annotations, shortLabels):\n",
    "\n",
    "    countPerLabel = pd.DataFrame(columns=shortLabels, index=[\"count\"])\n",
    "\n",
    "    for label in shortLabels:\n",
    "        countPerLabel.loc[\"count\", label] = len(annotations.loc[annotations[label] == 1.0])\n",
    "\n",
    "    return countPerLabel\n",
    "\n",
    "\n",
    "annotations = labelPortion(f\"../data/input_test_data_{hash}.csv\", labels=labels, shortLabels=shortLabels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sentiment_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "273380770c88f147a8cb2b1930f7fbdde5d761ff45d8be7992df3eb72e75f155"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
