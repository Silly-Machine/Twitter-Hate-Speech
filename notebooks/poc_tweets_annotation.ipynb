{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "from pigeonXT import annotate\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash():\n",
    "    return \"%08x\" % random.getrandbits(32)\n",
    "\n",
    "\n",
    "hash = hash()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MONGO_HOST = \"mongodb://localhost/twitterdb\"\n",
    "client = MongoClient(MONGO_HOST)\n",
    "raw_tweets = client.twitterdb.tweets_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>id_str</th>\n",
       "      <th>full_text</th>\n",
       "      <th>truncated</th>\n",
       "      <th>display_text_range</th>\n",
       "      <th>entities</th>\n",
       "      <th>metadata</th>\n",
       "      <th>source</th>\n",
       "      <th>...</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>favorited</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>lang</th>\n",
       "      <th>query</th>\n",
       "      <th>extended_entities</th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>quoted_status_id</th>\n",
       "      <th>quoted_status_id_str</th>\n",
       "      <th>quoted_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1491</th>\n",
       "      <td>62f3fbe2ef45b02417c6518a</td>\n",
       "      <td>Wed Aug 10 04:47:56 +0000 2022</td>\n",
       "      <td>1557227224293597186</td>\n",
       "      <td>1557227224293597186</td>\n",
       "      <td>@lybrjack Uma boa questão, um amigo meu pergun...</td>\n",
       "      <td>False</td>\n",
       "      <td>[10, 270]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'pt', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>pt</td>\n",
       "      <td>jeito de gay</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>62f3ef217a58ae552109c8fe</td>\n",
       "      <td>Wed Aug 10 14:04:29 +0000 2022</td>\n",
       "      <td>1557367283856596992</td>\n",
       "      <td>1557367283856596992</td>\n",
       "      <td>@JoaquinTeixeira @jairbolsonaro sei não, esse ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[32, 73]</td>\n",
       "      <td>{'hashtags': [], 'symbols': [], 'user_mentions...</td>\n",
       "      <td>{'iso_language_code': 'pt', 'result_type': 're...</td>\n",
       "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>pt</td>\n",
       "      <td>cara de macaco</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           _id                      created_at  \\\n",
       "1491  62f3fbe2ef45b02417c6518a  Wed Aug 10 04:47:56 +0000 2022   \n",
       "450   62f3ef217a58ae552109c8fe  Wed Aug 10 14:04:29 +0000 2022   \n",
       "\n",
       "                       id               id_str  \\\n",
       "1491  1557227224293597186  1557227224293597186   \n",
       "450   1557367283856596992  1557367283856596992   \n",
       "\n",
       "                                              full_text  truncated  \\\n",
       "1491  @lybrjack Uma boa questão, um amigo meu pergun...      False   \n",
       "450   @JoaquinTeixeira @jairbolsonaro sei não, esse ...      False   \n",
       "\n",
       "     display_text_range                                           entities  \\\n",
       "1491          [10, 270]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "450            [32, 73]  {'hashtags': [], 'symbols': [], 'user_mentions...   \n",
       "\n",
       "                                               metadata  \\\n",
       "1491  {'iso_language_code': 'pt', 'result_type': 're...   \n",
       "450   {'iso_language_code': 'pt', 'result_type': 're...   \n",
       "\n",
       "                                                 source  ...  favorite_count  \\\n",
       "1491  <a href=\"https://mobile.twitter.com\" rel=\"nofo...  ...               0   \n",
       "450   <a href=\"https://mobile.twitter.com\" rel=\"nofo...  ...               0   \n",
       "\n",
       "     favorited  retweeted lang           query extended_entities  \\\n",
       "1491     False      False   pt    jeito de gay               NaN   \n",
       "450      False      False   pt  cara de macaco               NaN   \n",
       "\n",
       "     possibly_sensitive quoted_status_id quoted_status_id_str quoted_status  \n",
       "1491                NaN              NaN                  NaN           NaN  \n",
       "450                 NaN              NaN                  NaN           NaN  \n",
       "\n",
       "[2 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df = pd.DataFrame(list(raw_tweets.find()))\n",
    "raw_df.sample(2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1555630597527199746</td>\n",
       "      <td>@0ravl4 @hoje_no Além de petralha a safada ain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1557015903224700929</td>\n",
       "      <td>NÃO existe \"coxinha sem massa\",bando de burro pqp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1556198185059684362</td>\n",
       "      <td>@heldermaldonado Coxinha burro!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1555581110880436224</td>\n",
       "      <td>Ser petista é ser burro para mas de metro , pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1554478359375126528</td>\n",
       "      <td>Burro burro burro burro burro me ofereceram um...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                          full_text\n",
       "0  1555630597527199746  @0ravl4 @hoje_no Além de petralha a safada ain...\n",
       "1  1557015903224700929  NÃO existe \"coxinha sem massa\",bando de burro pqp\n",
       "2  1556198185059684362                   @heldermaldonado Coxinha burro!!\n",
       "3  1555581110880436224  Ser petista é ser burro para mas de metro , pa...\n",
       "4  1554478359375126528  Burro burro burro burro burro me ofereceram um..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "public_df = raw_df.copy()[[\"id\", \"full_text\"]]\n",
    "public_df.drop_duplicates(inplace=True)\n",
    "public_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1557422001073037312</td>\n",
       "      <td>eu sou muito boiola por essas duas sim 🥺🤏🏼\\n\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>1557213357341646853</td>\n",
       "      <td>@LeonelRadde E a Rosca, \\nQueima ou não Queima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>1557179504908460032</td>\n",
       "      <td>@jandira_feghali Chuta que é macumba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>1557415987045171202</td>\n",
       "      <td>vai se foder puta desgraçada vagabunda egoísta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2099</th>\n",
       "      <td>1557434423527849984</td>\n",
       "      <td>me sentindo gord*o</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                          full_text\n",
       "259   1557422001073037312  eu sou muito boiola por essas duas sim 🥺🤏🏼\\n\\n...\n",
       "300   1557213357341646853  @LeonelRadde E a Rosca, \\nQueima ou não Queima...\n",
       "977   1557179504908460032               @jandira_feghali Chuta que é macumba\n",
       "137   1557415987045171202  vai se foder puta desgraçada vagabunda egoísta...\n",
       "2099  1557434423527849984                                 me sentindo gord*o"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = public_df.sample(20)\n",
    "sample.to_csv(f\"../data/input_test_data_{hash}.csv\", index=False)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 - 20 of 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9f33e3abfd5409a8c2269a7499e8b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HTML(value='0 of 20 Examples annotated, Current Position: 0 ')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f89f5ed71e40c2bc637dd9b01505c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(ToggleButton(value=False, description='political'), ToggleButton(value=False, de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab01b1397cb844ca88b542b67e4c6685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu sou muito boiola por essas duas sim 🥺🤏🏼\n",
      "\n",
      "#motherlandforsalem\n",
      "\n",
      "https://t.co/wax5SnkXof ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@LeonelRadde E a Rosca, \n",
      "Queima ou não Queima??\n",
      "😎🤣🤣🤣🤣 ['lgbtphobia']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@jandira_feghali Chuta que é macumba ['religion']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vai se foder puta desgraçada vagabunda egoísta ignorante cadela azeda idiota ingrata irracional inconsequente otária audaciosa burra cu de franjo estranha chata atropelada cachorra merda vaca imbecil arrombada mimizenta esquisita esquizofrenica baranga lixo paranóica e mal comida ['sexism']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me sentindo gord*o ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "não tem graça nenhuma fazer piada com isso, imbecil ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@chris_schettine Eu tinha o hábito de falar sobre padrão estético questionável como \"baianice\" \"coisa de baiano\" \n",
      "Casei com uma filha de Baianos kkkkkkkkkkk ['xenophobia']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@ritmodetorcida Os cara quebram o portão pra invadir o lado do Vasco, em maior número não invadi e fica fazendo grito de macaco igual maluco... muito idiotas e peidão ainda por cima. ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "um bando de crente defendendo a cusadora pompeo, que vida triste ['religion']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@lecibrandao Vagabunda igual  o  #LuLADRAO ['political']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@thigagliasso Como diz o Guilherme Fiuza, é a esquerda caviar! ['political']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bolsonaro nunca se preocupou com os mais pobres. Nunca se preocupou com quem passa fome. Tentou de todas as maneiras dar um auxílio emergencial menor. E cancelou o auxílio sempre que teve oportunidade. Quando viu que esse auxílio compra votos dos mais necessitados, ele defendeu. https://t.co/OqIvxNutpW ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@luanaserra @hppoderoso @otiagoabreu Como figurinha da área eu discordo desse argumento. A gente tem que puxar o bonde junto. Tem muito espaço pro autismo? Então vai o autista e fala sobre as outras deficiências para o público dele... ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caralho que ódio desse bando de filha da puta… eu pedi um café com cookie e vou tomar meia hora de sol pra não quebrar a cara de ngm… ['other', 'not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@mariaislc Puta não q eu n sou tuas nega ['sexism', 'racism']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hj uma safada queria me passar nota falsa vontade de dar na cara dela q ódio ['sexism']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@reveloud ja pode contar pros seus seguidores q vc eh um velho tarado de 52 anos ['ageism']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@douglasdelete @CLMerlo Pesquisa ai a divida do teu time, vê lá quem deve mais. mongol burro! ['ableism']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vim fazer comprinhas no supermercado e comprei tanta besteira chocolates, doces etc parece que terminei mais um namoro mas é só a solidão do twink favelado mesmo https://t.co/3F2LWE1ezD ['not_applicable']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Já fiz assim, mas eu era jovem e burro. https://t.co/1M3LcbyrVT ['not_applicable']\n",
      "Annotation done.\n"
     ]
    }
   ],
   "source": [
    "labels = [\n",
    "    \"political\",\n",
    "    \"sexism\",\n",
    "    \"lgbtphobia\",\n",
    "    \"racism\",\n",
    "    \"aporophobia\",\n",
    "    \"xenophobia\",\n",
    "    \"ableism\",\n",
    "    \"ageism\",\n",
    "    \"religion\",\n",
    "    \"body_shame\",\n",
    "    \"other\",\n",
    "    \"not_applicable\",\n",
    "]\n",
    "\n",
    "shortLabels = [\"PL\", \"SX\", \"LGBT\", \"RC\", \"AP\", \"XP\", \"AB\", \"AG\", \"RL\", \"BS\", \"OT\", \"NA\"]\n",
    "\n",
    "\n",
    "def setLabels(labels, numClasses):\n",
    "    row = np.zeros([numClasses], dtype=np.uint8)\n",
    "    row[labels] = 1\n",
    "    return row\n",
    "\n",
    "\n",
    "def labelPortion(\n",
    "    inputFile,\n",
    "    labels=[\"yes\", \"no\"],\n",
    "    outputFile=f\"../data/output_test_data_{hash}.csv\",\n",
    "    portionSize=20,\n",
    "    textColumn=\"full_text\",\n",
    "    shortLabels=None,\n",
    "):\n",
    "\n",
    "    if shortLabels:\n",
    "        shortLabels = shortLabels\n",
    "    else:\n",
    "        shortLabels = labels\n",
    "\n",
    "    out = Path(outputFile)\n",
    "    if out.exists():\n",
    "        outdf = pd.read_csv(out)\n",
    "        currentId = outdf.index.max() + 1\n",
    "    else:\n",
    "        currentId = 0\n",
    "\n",
    "    indf = pd.read_csv(inputFile)\n",
    "    examplesInFile = len(indf)\n",
    "    indf = indf.loc[currentId : currentId + portionSize - 1]\n",
    "    actualPortionSize = len(indf)\n",
    "    print(f\"{currentId + 1} - {currentId + actualPortionSize} of {examplesInFile}\")\n",
    "    sentences = indf[textColumn].tolist()\n",
    "\n",
    "    for label in shortLabels:\n",
    "        indf[label] = None\n",
    "\n",
    "    def updateRow(example, selectedLabels):\n",
    "        print(example, selectedLabels)\n",
    "        labs = setLabels([labels.index(y) for y in selectedLabels], len(labels))\n",
    "        indf.loc[indf[textColumn] == example, shortLabels] = labs\n",
    "\n",
    "    def finalProcessing(annotations):\n",
    "        if out.exists():\n",
    "            prevdata = pd.read_csv(out)\n",
    "            outdata = pd.concat([prevdata, indf]).reset_index(drop=True)\n",
    "        else:\n",
    "            outdata = indf.copy()\n",
    "        outdata.to_csv(out, index=False)\n",
    "\n",
    "    _ = annotate(\n",
    "        sentences,\n",
    "        options=labels,\n",
    "        task_type=\"multilabel-classification\",\n",
    "        buttons_in_a_row=3,\n",
    "        reset_buttons_after_click=True,\n",
    "        include_next=False,\n",
    "        include_back=False,\n",
    "        example_process_fn=updateRow,\n",
    "        final_process_fn=finalProcessing,\n",
    "    )\n",
    "    return indf\n",
    "\n",
    "\n",
    "def getAnnotationsCountPerlabel(annotations, shortLabels):\n",
    "\n",
    "    countPerLabel = pd.DataFrame(columns=shortLabels, index=[\"count\"])\n",
    "\n",
    "    for label in shortLabels:\n",
    "        countPerLabel.loc[\"count\", label] = len(annotations.loc[annotations[label] == 1.0])\n",
    "\n",
    "    return countPerLabel\n",
    "\n",
    "\n",
    "annotations = labelPortion(f\"../data/input_test_data_{hash}.csv\", labels=labels, shortLabels=shortLabels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('sentiment_analysis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "273380770c88f147a8cb2b1930f7fbdde5d761ff45d8be7992df3eb72e75f155"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
